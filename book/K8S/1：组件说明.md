## 整体结构图

![image-20240108003330009](C:\Users\Bowen\AppData\Roaming\Typora\typora-user-images\image-20240108003330009.png)

<img src="https://img-blog.csdnimg.cn/f4688459d9a1496699596cb19cf11b44.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA54ixc2hvd-eahOWwj-WNpOibiw==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述" style="zoom: 67%;" />

上面两个图，一个是replication controller，一个是controller manager。它们其实是一个东西，都是用来复杂控制副本数量的。





## 在master中，有scheduler，replication controller/controller manager，api server，etcd

api：所有服务访问的统一入门

controller manager：控制副本数量的

scheduler： 选择合适的节点进行任务的分配

etcd： 分布式键值对存储服务，etcd是为了保存集群中需要保存的配置信息等文件

> 分布式键值对存储，什么是分布式？  分布式就是集群的意思：
>
> 可以参考一下这个：https://www.jianshu.com/p/677c11695e18   笔记尽量把东西都写明白
>
> <img src="C:\Users\Bowen\AppData\Roaming\Typora\typora-user-images\image-20240108005939798.png" alt="image-20240108005939798" style="zoom:80%;" />
>
> 
>
> ![image-20240108010046178](C:\Users\Bowen\AppData\Roaming\Typora\typora-user-images\image-20240108010046178.png)
>
> 在别人的博客中找到：**“etcd一般最佳内存在8G，太大太小都容易引起性能降低。所以我们不能拿etcd当做数据库使用，只能存储各种元数据信息。*
>  按照k8s的官方文档和业界的最佳实践，k8s可以管理到5000个节点，这么算每个节点可以分配到16M的存储。”*
>
> 
>
> ###### 所以从图中和从别人的博客中的发现来看：
>
> etcd是分布在所有的k8s节点中的，从而实现分布式存储功能

## 在worker中：

1：kubelet：

> 和docker容器引擎通信，操作docker启动容器 （一句话： 启动容器的）

2： kube proxy

> 1：pod之间通信； 2：负载均衡的实现

## pod的创建流程：

<img src="https://img2023.cnblogs.com/blog/2139314/202303/2139314-20230313103442490-1601810554.png" alt="img"  />

<font color=LightGreen>简单一点就是： 用户给api说想创建一个pod；  scheduler看一下给分配哪一个节点好一点，通知那个节点的kubelet； kubelet开始创建pod</font>



![img](https://img2023.cnblogs.com/blog/2139314/202303/2139314-20230313103421404-1752299491.png)